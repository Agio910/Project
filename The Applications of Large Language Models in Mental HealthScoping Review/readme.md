# Large Language Models in Mental Health: Scoping Review

## Overview

This scoping review examines the applications of large language models (LLMs) in mental health, identifying trends, application areas, performance comparisons, challenges, and future directions. The review analyzed 95 peer-reviewed articles published between January 2019 and August 2024 from various international databases.

## paper information
- https://www.jmir.org/2025/1/e69284
- published in Journal of Medical Internet Research

## Repository Contents

- **LLM_fig**: Contains high-resolution figures illustrating the comparison between LLMs, non-transformer models, and humans; geographic distribution of studies; application frameworks; and performance comparisons
- **Supplementary Materials**: Includes detailed search terms, excluded studies, categorization of articles, performance metrics, and comparative analyses between different LLM types

## Key Findings

The applications of LLMs in mental health were categorized into three main areas:
- Screening or detection of mental disorders (71% of studies)
- Supporting clinical treatments and interventions (33%)
- Assisting in mental health counseling and education (12%)

Most studies focused on depression detection and classification (35%), clinical treatment support (15%), and suicide risk prediction (13%).

## Advantages of LLMs in Mental Health

Compared to traditional models and human clinicians, LLMs demonstrate enhanced capabilities in:
- Information acquisition and analysis
- Generating natural language responses
- Handling large-scale data
- Supporting preliminary mental health care
- Data augmentation for improving clinical datasets

## Challenges and Ethical Considerations

The review identifies several challenges:
- Privacy concerns with sensitive health data
- Potential biases in model training and outputs
- Limitations in empathy and emotional intelligence
- Need for human oversight and professional intervention
- Ethical standards for clinical applications

## Future Directions

Promising directions for future development include:
- Integration of multimodal data (text, images, audio)
- Expansion to diverse mental health conditions
- Improvements in accuracy and reliability
- Development of domain-specific fine-tuned models
- Standards for privacy, safety, and ethical use


This review provides valuable insights for researchers, clinicians, and developers working with LLMs in mental health applications, highlighting both the potential and limitations of these technologies.